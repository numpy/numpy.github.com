<!doctype html><html lang=ja data-colorscheme=light><head><meta name=description content="NumPyが広く利用される理由 強力な多次元配列、数値計算ツール群、相互運用性、高いパフォーマンス、オープンソース"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=x-ua-compatible content="ie=edge"><title>NumPy - ケーススタディ: DeepLabCut 三次元姿勢推定</title>
<link rel=icon href=/images/favicon.ico><link rel=stylesheet type=text/css href=/theme-css/sphinx-design/index.scss.min.36ff85d5815ecbee58c1ba27bcc5efe301092254f8ab00f2f53a72e4222d58ee.css integrity="sha256-Nv+F1YFey+5YwbonvMXv4wEJIlT4qwDy9Tpy5CItWO4="><link rel=stylesheet type=text/css href=/theme-css/pst/bootstrap.scss.min.87f6567658abd7c689e5136c0fbfad108339a433c326f43b675049ae49720bad.css integrity="sha256-h/ZWdlir18aJ5RNsD7+tEIM5pDPDJvQ7Z1BJrklyC60="><link rel=stylesheet type=text/css href=/theme-css/pst/pydata-sphinx-theme.scss.min.e4029059255c0ce7257cdeb76ea19320bbc50c3ab32d8351228ac135304237a9.css integrity="sha256-5AKQWSVcDOclfN63bqGTILvFDDqzLYNRIorBNTBCN6k="><link rel=stylesheet type=text/css href=/theme-css/spht/index.scss.min.ad03de1683bb39a0d1b31395797b97188e59cda6d778c0671a99db0b4fb799a9.css integrity="sha256-rQPeFoO7OaDRsxOVeXuXGI5ZzabXeMBnGpnbC0+3mak="><link rel=stylesheet type=text/css href=/css/tabs.scss.min.549aba196cc14bca7747a312ff35df0aa1f486b740c19ee0c88aaa721fb8c2e1.css integrity="sha256-VJq6GWzBS8p3R6MS/zXfCqH0hrdAwZ7gyIqqch+4wuE="><link rel=stylesheet href=/theme-css/backtotop.min.b5f58df56ca9d2f2b749b8d5eb4ab2b5a1724c63cbd24b2f8a0b0c2268e1eca4.css integrity="sha256-tfWN9Wyp0vK3SbjV60qytaFyTGPL0ksvigsMImjh7KQ="><link rel=stylesheet href=/theme-css/bulma.min.f488b160722c9b7a2a760c03808dc8df5173e6c9dd25cb7481451ddb3c4f35dc.css integrity="sha256-9IixYHIsm3oqdgwDgI3I31Fz5sndJct0gUUd2zxPNdw="><link rel=stylesheet href=/theme-css/code-highlight.min.d0bd96ff1dbeb4b62536da5935b92af5cd7edb6d6f52b316d721e62078d9f089.css integrity="sha256-0L2W/x2+tLYlNtpZNbkq9c1+221vUrMW1yHmIHjZ8Ik="><link rel=stylesheet href=/theme-css/content.min.1de9b096ffc099fee4b538589fea6b622be33d69de64c451e11f2c91476029c5.css integrity="sha256-Hemwlv/Amf7ktThYn+prYivjPWneZMRR4R8skUdgKcU="><link rel=stylesheet href=/theme-css/dark-mode.min.1a7d04742ddf658331233b701507a0124657cbf45e02c672c061955181de6dde.css integrity="sha256-Gn0EdC3fZYMxIztwFQegEkZXy/ReAsZywGGVUYHebd4="><link rel=stylesheet href=/theme-css/footer.min.4be63c4d5628cb485efcfa5c9475fa1daa18933eb83741a2ca2bcd444ec270a2.css integrity="sha256-S+Y8TVYoy0he/PpclHX6HaoYkz64N0GiyivNRE7CcKI="><link rel=stylesheet href=/theme-css/hero.min.aa8286fd7d31d78e297e71594436c47b17d4f28660fd16f2b252e3f55fa500be.css integrity="sha256-qoKG/X0x144pfnFZRDbEexfU8oZg/RbyslLj9V+lAL4="><link rel=stylesheet href=/theme-css/lists.min.83821789384ebadc1a1ff75ef9f4b29ba53fe45eb30a46a228aa55772a393396.css integrity="sha256-g4IXiThOutwaH/de+fSym6U/5F6zCkaiKKpVdyo5M5Y="><link rel=stylesheet href=/theme-css/navbar.min.c15f7eadb5a7e1532309c04d94e1b0099d4fa75aaded30829bbfd21ebdb51ad5.css integrity="sha256-wV9+rbWn4VMjCcBNlOGwCZ1Pp1qt7TCCm7/SHr21GtU="><link rel=stylesheet href=/theme-css/news.min.8875ffae62ae22741a27025581fcb3341c18442be06bf132e45f8d6027692876.css integrity="sha256-iHX/rmKuInQaJwJVgfyzNBwYRCvga/Ey5F+NYCdpKHY="><link rel=stylesheet href=/theme-css/posts.min.9505f87d5973f3f08c99c613c0781b3a42411f4795657e8da7ef29c7ad37c23d.css integrity="sha256-lQX4fVlz8/CMmcYTwHgbOkJBH0eVZX6Np+8px603wj0="><link rel=stylesheet href=/theme-css/shortcuts.min.f90addf0a2a3c4e075eb5c3c78e4cc27d9b4fba18a02a17808695212762224c1.css integrity="sha256-+Qrd8KKjxOB161w8eOTMJ9m0+6GKAqF4CGlSEnYiJME="><link rel=stylesheet href=/theme-css/styles.min.8b4e167f94e0c2a515ad1c586c0ccf14a951081984e9b11f54c48ed850bac12e.css integrity="sha256-i04Wf5TgwqUVrRxYbAzPFKlRCBmE6bEfVMSO2FC6wS4="><link rel=stylesheet href=/theme-css/tables.min.7a44b6bd698323dd3d379b714bd534132e76bf4ba0d3dec61997a8d9ba9db5fb.css integrity="sha256-ekS2vWmDI909N5txS9U0Ey52v0ug097GGZeo2bqdtfs="><link rel=stylesheet href=/theme-css/tabs.min.8884c317231b5f2331b2fd9f65e4f7900fe9124aafae93b78cef175960289683.css integrity="sha256-iITDFyMbXyMxsv2fZeT3kA/pEkqvrpO3jO8XWWAoloM="><link rel=stylesheet href=/theme-css/vars.min.3d537d14ea6e6fb59012fa9d357adf4b209dab8c2535fb94ab37afb6a37020fd.css integrity="sha256-PVN9FOpub7WQEvqdNXrfSyCdq4wlNfuUqzevtqNwIP0="><link rel=stylesheet href=/theme-css/videos.min.41c135abe8361308f9258975985342fc3107ddc6440698251dd72e2b909cdaaa.css integrity="sha256-QcE1q+g2Ewj5JYl1mFNC/DEH3cZEBpglHdcuK5Cc2qo="><link rel=stylesheet href=/css/casestudies.min.92b0bafc1e58181b02c23f14b861767269e505eadc85a123b4eb79e2527bf2e0.css integrity="sha256-krC6/B5YGBsCwj8UuGF2cmnlBerchaEjtOt54lJ78uA="><link rel=stylesheet href=/css/custom.min.cf0f0187caa046832f55197d09d0ad54a98eebc7758bbb354fb1c8fb8541b5bb.css integrity="sha256-zw8Bh8qgRoMvVRl9CdCtVKmO68d1i7s1T7HI+4VBtbs="><link rel=stylesheet href=/css/mailchimp.min.96f403ea4c8be10747beb4c33a219da2fa8234a3b98882983bd2569da8eeb9e1.css integrity="sha256-lvQD6kyL4QdHvrTDOiGdovqCNKO5iIKYO9JWnajuueE="><link rel=stylesheet href=/css/shell.min.173478d133f6f5990705f3ed2f48714422de15754d813df6aa2a047bf62a51da.css integrity="sha256-FzR40TP29ZkHBfPtL0hxRCLeFXVNgT32qioEe/YqUdo="><script src=https://code.jquery.com/jquery-3.7.1.min.js></script><link rel=alternate hreflang=en href=/case-studies/deeplabcut-dnn/ title=English><link rel=alternate hreflang=pt href=/pt/case-studies/deeplabcut-dnn/ title=Português><link rel=alternate hreflang=es href=/es/case-studies/deeplabcut-dnn/ title=Español><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://numpy.org/images/numpy-image.jpg"><meta name=twitter:title content="ケーススタディ: DeepLabCut 三次元姿勢推定"><meta name=twitter:description content="DeepLapCutを用いたマウスの手の動きの解析#
(Source: www.deeplabcut.org ) オープンソースソフトウェアは生体臨床医学を加速させています。 DeepLabCut を使用すると、深層学習を使用して動物の行動を自動的にビデオ解析することができます。 —Alexander Mathis、 准教授、École polytechnology fe’rale de Lausanne (EPFL)
DeepLabCut について# DeepLabCutは、ごくわずかなトレーニングデータで人間レベルの精度で実験動物の行動を追跡可能にするオープンソースのツールボックスです。 DeepLabCutの技術を使うことで、科学者は動物の種類と時系列のデータをもとに、運動制御と行動に関する科学的な理解を深めることができるようになりました。
神経科学、医学、生体力学などのいくつかの研究分野では、動物の動きを追跡したデータを使用しています。 DeepLabCutは、動画に記録された動きを解析することで、人間やその他の動物が何をしているのかを理解することができます。 タグ付けや監視などの、手間のかかる作業を自動化し、深層学習ベースのデータ解析を実施します。 DeepLabCutは、霊長類、マウス、魚、ハエなどの動物を観察する科学研究をより速く正確にしています。
色のついた点は競走馬の体の位置を追跡#
(Source: Mackenzie Mathis) DeepLabCutは、動物の姿勢を抽出することで非侵襲的な行動追跡を行います。 これは、生体力学、遺伝学、倫理学、神経科学などの分野での研究に必要不可欠です。 動的に変化する背景の中で、動物の姿勢をビデオデータから非侵襲的に測定することは、技術的にも、必要な計算リソースやトレーニングデータの点でも、非常に困難な計算処理です。
DeepLabCutは、研究者が対象の姿勢を推定し、Pythonベースのソフトウェアを使って効率的に対象の行動を定量化することを可能にします。 DeepLabCutを使用すると、研究者は動画から異なるフレームを識別し、数十個のフレームの特定の身体部位を、よくできたGUIによってラベルづけできます。 すると、DeepLabCutの深層学習ベースのポーズ推定アーキテクチャにより、動画の残りの部分や動物の他の類似した動画から同じ特徴を抽出する方法を学習できます。 ハエやマウスなどの一般的な実験動物から チーターのようなより珍しい動物まで、動物の種類を問わず利用できます。
DeepLabCutでは転移学習という技術を使用しています。 これにより必要な学習データの量を大幅に削減し、学習の収束を加速させることができます。 必要に応じて、より高速な推論を提供するさまざまなネットワークアーキテクチャ(MobileNetV2など)を選択することができ、リアルタイムの実験データフィードバックと組み合わせることもできます。 DeepLabCutはもともとDeeperCutと呼ばれるパフォーマンスのよい人用のポーズ推定アーキテクチャの特徴検出器を使用しており、これが名前の由来になりました。 今ではこのパッケージは大幅に変更され、追加のアーキテクチャ・データの水増し・一通りのユーザー用フロントエンドを含んでいます。 さらに、 大規模な生物学的実験をサポートするため、DeepLabCutはオンライン学習の機能を提供しています。 これにより、動画の時間をこえて学習データを増やすことができ、エッジケースをカバーしたり、特定のコンテキスト内でポーズ推定アルゴリズムを堅牢にしたりできます。
最近、DeepLabCut model zooが発表されました。 これは、霊長類の顔分析から犬の姿勢まで、様々な種や実験条件に対応した事前訓練済みモデルを提供しています。 これにより、例えば、新しいデータのラベルを付けることなくクラウドで予測を実行することができたり、ニューラルネットワークの学習を実行することができます。 プログラミング経験は必要ありません。
主な目標と結果# 科学研究のための動物姿勢解析の自動化:
DeepLabCutという技術の主な目的は、多様な環境で動物の姿勢を測定し追跡することです。 このデータは例えば神経科学の研究において、脳がどのように運動を制御しているかを理解するためのや、動物がどのように社会的に交流しているかを明らかにするために利用することができます。 研究者はDeepLabCutで 10倍のパフォーマンス向上 が可能であると発表しています。 オフラインでは最大1200フレーム/秒(FPS) で姿勢を推定することができます。
姿勢推定のための使いやすいPythonツールキットの作成:
DeepLabCutは、動物の姿勢推定技術を研究者が簡単に利用できるツールとして共有したいという考えから開発されています。 そこで開発者らはプロジェクト管理機能を備えた、単独で機能し、使いやすいPythonツールボックスとしてこのツールを作成しました。 これにより、姿勢推定を自動化するだけでなく、DeepLabCutツールキットユーザーをデータセット収集段階から共有可能・再利用可能な分析パイプラインを作成する段階まで補助し、プロジェクトをエンドツーエンドで管理することも可能になりました。
このツールキット はオープンソースとして利用できます。
典型的なDeepLabCutワークフローは以下のようになります。
オンライン学習によるトレーニングセットの作成と調整 特定の動物やシナリオに合わせたニューラルネットワークの構築 動画における大規模推論のためのコード作成 統合された可視化ツールを使用した推論の描画 DeepLabCutによる姿勢推定のステップ#"></head><body><nav id=nav class=navbar role=navigation aria-label="main navigation"><div class=container><div class=navbar-brand><a class=navbar-item href=/ja/><img class=navbar-logo src=/images/logo.svg alt="%!s(<nil>) logo"><div class=navbar-logo-text>NumPy</div></a><a role=button class=navbar-burger aria-label=menu aria-expanded=false data-target=navbar-menu><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a></div><div id=navbar-menu class=navbar-menu><div class=navbar-end><a href=/ja/install class=navbar-item>インストール
</a><a href=https://numpy.org/doc/stable class=navbar-item>ドキュメント
</a><a href=/ja/learn class=navbar-item>学び方
</a><a href=/ja/community class=navbar-item>コミュニティ
</a><a href=/ja/about class=navbar-item>私達について
</a><a href=/ja/news class=navbar-item>ニュース
</a><a href=/ja/contribute class=navbar-item>NumPyに貢献する</a><div class="navbar-item has-dropdown"><a aria-label="Select language" class=navbar-link>日本語 (Japanese)</a><div class=navbar-dropdown><a href=/case-studies/deeplabcut-dnn/ class=navbar-item>English
</a><a href=/pt/case-studies/deeplabcut-dnn/ class=navbar-item>Português
</a><a href=/es/case-studies/deeplabcut-dnn/ class=navbar-item>Español</a></div></div></div></div></div></nav><section class=content-padding><div class=content-container><nav aria-label=Breadcrumb><ul id=breadcrumbs class=bd-breadcrumbs><li class="breadcrumb-item breadcrumb-home"><a href=/ja/ class=nav-link aria-label=Home><i class="fas fa-home"></i></a></li><li class=breadcrumb-item><a href=/ja/case-studies/ class=nav-link>Case-Studies</a></li><li class="breadcrumb-item active" aria-current=page>ケーススタディ: DeepLabCut 三次元姿勢推定</li></ul></nav><h1>ケーススタディ: DeepLabCut 三次元姿勢推定</h1><div><figure class=align-default id=id000><img src=/images/content_images/cs/mice-hand.gif alt=micehandanim class=align-center><figcaption><strong class=caption-title>DeepLapCutを用いたマウスの手の動きの解析</strong><a class=headerlink href=#id000 title="Link to this image">#</a><br><a href=http://www.mousemotorlab.org/deeplabcut>(Source: www.deeplabcut.org )</a><p><span class=caption-text></span></figcaption></figure><blockquote cite=https://news.harvard.edu/gazette/story/newsplus/harvard-researchers-awarded-czi-open-source-award/><p>オープンソースソフトウェアは生体臨床医学を加速させています。 DeepLabCut を使用すると、深層学習を使用して動物の行動を自動的にビデオ解析することができます。</p><p class=attribution>—Alexander Mathis、 <em>准教授、École polytechnology fe’rale de Lausanne</em> (<a href=https://www.epfl.ch/en/>EPFL</a>)</p></blockquote><h2 id=deeplabcut-について>DeepLabCut について<a class=headerlink href=#deeplabcut-について title="Link to this heading">#</a></h2><p><a href=https://github.com/DeepLabCut/DeepLabCut>DeepLabCut</a>は、ごくわずかなトレーニングデータで人間レベルの精度で実験動物の行動を追跡可能にするオープンソースのツールボックスです。 DeepLabCutの技術を使うことで、科学者は動物の種類と時系列のデータをもとに、運動制御と行動に関する科学的な理解を深めることができるようになりました。</p><p>神経科学、医学、生体力学などのいくつかの研究分野では、動物の動きを追跡したデータを使用しています。 DeepLabCutは、動画に記録された動きを解析することで、人間やその他の動物が何をしているのかを理解することができます。 タグ付けや監視などの、手間のかかる作業を自動化し、深層学習ベースのデータ解析を実施します。 DeepLabCutは、霊長類、マウス、魚、ハエなどの動物を観察する科学研究をより速く正確にしています。</p><figure class=align-default id=id002><img src=/images/content_images/cs/race-horse.gif alt=horserideranim class=align-center><figcaption><strong class=caption-title>色のついた点は競走馬の体の位置を追跡</strong><a class=headerlink href=#id002 title="Link to this image">#</a><br>(Source: Mackenzie Mathis)<p><span class=caption-text></span></figcaption></figure><p>DeepLabCutは、動物の姿勢を抽出することで非侵襲的な行動追跡を行います。 これは、生体力学、遺伝学、倫理学、神経科学などの分野での研究に必要不可欠です。 動的に変化する背景の中で、動物の姿勢をビデオデータから非侵襲的に測定することは、技術的にも、必要な計算リソースやトレーニングデータの点でも、非常に困難な計算処理です。</p><p>DeepLabCutは、研究者が対象の姿勢を推定し、Pythonベースのソフトウェアを使って効率的に対象の行動を定量化することを可能にします。 DeepLabCutを使用すると、研究者は動画から異なるフレームを識別し、数十個のフレームの特定の身体部位を、よくできたGUIによってラベルづけできます。 すると、DeepLabCutの深層学習ベースのポーズ推定アーキテクチャにより、動画の残りの部分や動物の他の類似した動画から同じ特徴を抽出する方法を学習できます。 ハエやマウスなどの一般的な実験動物から <a href=https://www.technologynetworks.com/neuroscience/articles/interview-a-deeper-cut-into-behavior-with-mackenzie-mathis-327618>チーター</a>のようなより珍しい動物まで、動物の種類を問わず利用できます。</p><p>DeepLabCutでは<a href=https://arxiv.org/pdf/1909.11229>転移学習</a>という技術を使用しています。 これにより必要な学習データの量を大幅に削減し、学習の収束を加速させることができます。 必要に応じて、より高速な推論を提供するさまざまなネットワークアーキテクチャ(MobileNetV2など)を選択することができ、リアルタイムの実験データフィードバックと組み合わせることもできます。 DeepLabCutはもともと<a href=https://arxiv.org/abs/1605.03170>DeeperCut</a>と呼ばれるパフォーマンスのよい人用のポーズ推定アーキテクチャの特徴検出器を使用しており、これが名前の由来になりました。 今ではこのパッケージは大幅に変更され、追加のアーキテクチャ・データの水増し・一通りのユーザー用フロントエンドを含んでいます。 さらに、 大規模な生物学的実験をサポートするため、DeepLabCutはオンライン学習の機能を提供しています。 これにより、動画の時間をこえて学習データを増やすことができ、エッジケースをカバーしたり、特定のコンテキスト内でポーズ推定アルゴリズムを堅牢にしたりできます。</p><p>最近、<a href=http://www.mousemotorlab.org/dlc-modelzoo>DeepLabCut model zoo</a>が発表されました。 これは、霊長類の顔分析から犬の姿勢まで、様々な種や実験条件に対応した事前訓練済みモデルを提供しています。 これにより、例えば、新しいデータのラベルを付けることなくクラウドで予測を実行することができたり、ニューラルネットワークの学習を実行することができます。 プログラミング経験は必要ありません。</p><h3 id=主な目標と結果>主な目標と結果<a class=headerlink href=#主な目標と結果 title="Link to this heading">#</a></h3><ul><li><p><strong>科学研究のための動物姿勢解析の自動化:</strong></p><p>DeepLabCutという技術の主な目的は、多様な環境で動物の姿勢を測定し追跡することです。 このデータは例えば神経科学の研究において、脳がどのように運動を制御しているかを理解するためのや、動物がどのように社会的に交流しているかを明らかにするために利用することができます。 研究者はDeepLabCutで <a href=https://www.biorxiv.org/content/10.1101/457242v1>10倍のパフォーマンス向上</a> が可能であると発表しています。 オフラインでは最大1200フレーム/秒(FPS) で姿勢を推定することができます。</p></li><li><p><strong>姿勢推定のための使いやすいPythonツールキットの作成:</strong></p><p>DeepLabCutは、動物の姿勢推定技術を研究者が簡単に利用できるツールとして共有したいという考えから開発されています。 そこで開発者らはプロジェクト管理機能を備えた、単独で機能し、使いやすいPythonツールボックスとしてこのツールを作成しました。 これにより、姿勢推定を自動化するだけでなく、DeepLabCutツールキットユーザーをデータセット収集段階から共有可能・再利用可能な分析パイプラインを作成する段階まで補助し、プロジェクトをエンドツーエンドで管理することも可能になりました。</p><p>この<a href=https://github.com/DeepLabCut/DeepLabCut>ツールキット</a> はオープンソースとして利用できます。</p><p>典型的なDeepLabCutワークフローは以下のようになります。</p><ul><li>オンライン学習によるトレーニングセットの作成と調整</li><li>特定の動物やシナリオに合わせたニューラルネットワークの構築</li><li>動画における大規模推論のためのコード作成</li><li>統合された可視化ツールを使用した推論の描画</li></ul></li></ul><figure class=align-center id=id003><img src=/images/content_images/cs/deeplabcut-toolkit-steps.png alt=dlcsteps class=align-center><figcaption><strong class=caption-title>DeepLabCutによる姿勢推定のステップ</strong><a class=headerlink href=#id003 title="Link to this image">#</a><br><a href=https://twitter.com/DeepLabCut/status/1198046918284210176/photo/1>(Source: DeepLabCut)</a><p><span class=caption-text></span></figcaption></figure><h3 id=課題>課題<a class=headerlink href=#課題 title="Link to this heading">#</a></h3><ul><li><p><strong>速度</strong></p><p>動物行動動画の高速な処理は、動物の行動を測定し、科学実験をより効率的で正確にするために重要です。 動的に変化する背景の中で、マーカーを使用せずに、実験室での実験のために動物の詳細な姿勢を抽出することは、技術的にも、必要なリソース的にも、必要なトレーニングデータの面でも、困難な場合があります。 科学者が、より現実的な状況で研究を行うために、コンピュータビジョンなどの専門知識のスキルを必要とせずに使うことができるツールを開発することは、解決すべき重要な問題です。</p></li><li><p><strong>組み合わせ問題</strong></p><p>組合せ問題とは、複数の四肢の動きを個々の動物行動に統合することを指します。 キーポイントと、その個々の動物行動との関連性を組み合わせ、時間的に結びつけることは、複雑なプロセスであり、非常に膨大な数値解析が必要となります。 特に、実験映像の中で複数の動物の動きを追跡する場合は大変です。</p></li><li><p><strong>データ処理</strong></p><p>最後に、配列の操作もかなり難しい問題です。 様々な画像や、目標のテンソル、キーポイントに対応する大きな配列のスタックを処理しなければならないからです。</p></li></ul><figure class=align-center id=id004><img src=/images/content_images/cs/pose-estimation.png alt=challengesfig class=align-center><figcaption><strong class=caption-title>姿勢推定の多様性と難しさ</strong><a class=headerlink href=#id004 title="Link to this image">#</a><br><a href=https://www.biorxiv.org/content/10.1101/476531v1.full.pdf>(Source: Mackenzie Mathis)</a><p><span class=caption-text></span></figcaption></figure><h2 id=姿勢推定の課題に対応するためのnumpyの役割>姿勢推定の課題に対応するためのNumPyの役割<a class=headerlink href=#姿勢推定の課題に対応するためのnumpyの役割 title="Link to this heading">#</a></h2><p>NumPy は DeepLabCutにおける、行動分析の高速化のための数値計算の核となっています。 NumPyだけでなく、DeepLabCutは様々なNumPyをベースとしているPythonライブラリを利用しています。 <a href=https://www.scipy.org>SciPy</a>、<a href=https://pandas.pydata.org>Pandas</a>、<a href=https://matplotlib.org>matplotlib</a>、<a href=https://github.com/tensorpack/tensorpack>Tensorpack</a>, <a href=https://github.com/aleju/imgaug>imgaug</a>、<a href=https://scikit-learn.org/stable/>scikit-learn</a>、<a href=https://scikit-image.org>scikit-image</a>、<a href=https://www.tensorflow.org>Tensorflow</a>などです。</p><p>以下に挙げるNumPyの特徴が、DeepLabCutの姿勢推定アルゴリズムでの画像処理・組み合わせ処理・高速計算において、重要な役割を果たしました。</p><ul><li>ベクトル化</li><li>マスクされた配列操作</li><li>線形代数</li><li>ランダムサンプリング</li><li>大きな配列の再構成</li></ul><p>DeepLabCutは、ツールキットが提供するワークフローを通じてNumPyの配列機能を利用しています。 特に、NumPyはヒューマンアノテーションのラベル付けや、アノテーションの書き込み、編集、処理のために、特定のフレームをサンプリングするために使用されています。 TensorFlowを使ったニューラルネットワークは、DeepLabCutの技術によって何千回も訓練され、 フレームから真のアノテーション情報を予測します。 この目的のため、姿勢推定問題を画像-画像変換問題として変換する目標密度(スコアマップ) を作成します。 ニューラルネットワークのロバスト化のため、データの水増しを使用していますが、このためには幾何学・画像的処理を施したスコアマップの計算を行うことが必要になります。 また学習を高速化するため、NumPyのベクトル化機能が利用されています。 推論には、目標のスコアマップから最も可能性の高い予測値を抽出し、効率的に「予測値をリンクさせて個々の動物を組み立てる」ことが必要になります。</p><figure class=align-default id=id005><img src=/images/content_images/cs/deeplabcut-workflow.png alt=workflow class=align-center><figcaption><strong class=caption-title>DeepLabCutのワークフロー</strong><a class=headerlink href=#id005 title="Link to this image">#</a><br><a href=https://www.researchgate.net/figure/DeepLabCut-work-flow-The-diagram-delineates-the-work-flow-as-well-as-the-directory-and_fig1_329185962>(Source: Mackenzie Mathis)</a><p><span class=caption-text></span></figcaption></figure><h2 id=まとめ>まとめ<a class=headerlink href=#まとめ title="Link to this heading">#</a></h2><p>行動を観察し、効率的に表現することは、現代倫理学、神経科学、医学、工学の根幹です。 <a href=http://orga.cvss.cc/wp-content/uploads/2019/05/NathMathis2019.pdf>DeepLabCut</a> により、研究者は対象の姿勢を推定し、行動を効率的に定量化できるようになりました。 DeepLabCutというPythonツールボックスを使えば、わずかな学習画像のセットでニューラルネットワークを人間レベルのラベリング精度で学習することができ、実験室での行動分析だけでなく、スポーツ、歩行分析、医学、リハビリテーション研究などへの応用が可能になります。 DeepLabCutアルゴリズムに必要な複雑な組み合わせ処理やデータ処理の問題を、NumPyの配列操作機能が解決しています。</p><figure class=align-default id=id006><img src=/images/content_images/cs/numpy_dlc_benefits.png alt="numpy benefits" class=align-center><figcaption><strong class=caption-title>NumPyの主要機能</strong><a class=headerlink href=#id006 title="Link to this image">#</a><br><p><span class=caption-text></span></figcaption></figure></div></div><div id=shortcuts-container><div id=shortcuts><div id=shortcuts-header><i class="fa-solid fa-list"></i> On this page</div></div></div></section><div id=backtotop><a href=# id=backtotop-color><i class="fa-solid fa-arrow-up"></i></a></div><footer id=footer><div class=container><div id=footer-columns><div id=footer-logo-column><img id=footer-logo src=/images/logo.svg alt="NumPy logo. "></div><div class=footer-column><div class=footer-item><a href=/ja/install>インストール</a></div><div class=footer-item><a href=https://numpy.org/doc/stable>ドキュメント</a></div><div class=footer-item><a href=/ja/learn>学び方</a></div><div class=footer-item><a href=/ja/citing-numpy>引用する</a></div><div class=footer-item><a href=https://numpy.org/neps/roadmap.html>ロードマップ</a></div></div><div class=footer-column><div class=footer-item><a href=/ja/about>私達について</a></div><div class=footer-item><a href=/ja/community>コミュニティ</a></div><div class=footer-item><a href=/ja/user-surveys>ユーザーの調査</a></div><div class=footer-item><a href=/ja/contribute>NumPyに貢献する</a></div><div class=footer-item><a href=/ja/code-of-conduct>行動規範</a></div></div><div class=footer-column><div class=footer-item><a href=/ja/gethelp>サポートを得る方法</a></div><div class=footer-item><a href=/ja/terms>利用規約</a></div><div class=footer-item><a href=/ja/privacy>プライバシーポリシー</a></div><div class=footer-item><a href=/ja/press-kit>プレス用資料</a></div></div><div class=footer-actions>Sign up for the latest NumPy news, resources, and more<form action="https://numpy.us4.list-manage.com/subscribe/post?u=5ddd0d1d6e807900a8212481a&amp;id=287fa4253c" method=post id=mc-embedded-subscribe-form name=mc-embedded-subscribe-form class="validate sign-up-container" target=_blank novalidate><div class=sign-up-image><svg class="icon mail-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M22 6c0-1.1-.9-2-2-2H4c-1.1.0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1.0 2-.9 2-2V6zm-2 0-8 5-8-5h16zm0 12H4V8l8 5 8-5v10z"/></svg></div><input type=email name=EMAIL class="required email sign-up-input" id=mce-EMAIL aria-label="Input for email, press enter to submit" onkeypress='(event.which===13||event.keyCode===13||event.key==="Enter")&&sendThankYou()'><div class=submission-instructions>Press Enter</div><button class=signup-button onclick=sendThankYou() aria-label=Submit><svg class="icon sent-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M2.01 21 23 12 2.01 3 2 10l15 2-15 2z"/></svg></button><div id=mce-responses class=clear><div class=response id=mce-error-response style=display:none></div><div class=response id=mce-success-response style=display:none></div></div><div style=position:absolute;left:-5000px aria-hidden=true><input type=text name=b_5ddd0d1d6e807900a8212481a_287fa4253c tabindex=-1></div><div class=clear><input type=submit value=Subscribe name=subscribe id=mc-embedded-subscribe class=button style=display:none></div></form><div class=thank-you>Thank you! &#127881;</div><div class=community-icons><a href=https://github.com/numpy/numpy aria-label=https://github.com/numpy/numpy><svg class="icon github-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M12 .297c-6.63.0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577.0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93.0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176.0.0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22.0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22.0 1.606-.015 2.896-.015 3.286.0.315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
</a><a href=https://www.youtube.com/channel/UCguIL9NZ7ybWK5WQ53qbHng aria-label=https://www.youtube.com/channel/UCguIL9NZ7ybWK5WQ53qbHng><svg class="icon youtube-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M23.498 6.186A3.016 3.016.0 0021.376 4.05C19.505 3.545 12 3.545 12 3.545s-7.505.0-9.377.505A3.017 3.017.0 00.502 6.186C0 8.07.0 12 0 12s0 3.93.502 5.814a3.016 3.016.0 002.122 2.136c1.871.505 9.376.505 9.376.505s7.505.0 9.377-.505a3.015 3.015.0 002.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg></a></div><div class=copyright>&copy; 2024 NumPy team. All rights reserved.</div></div></div></div></footer></body><script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/js/all.min.js integrity=sha384-3ve3u7etWcm2heCe4TswfZSAYSg2jR/EJxRHuKM5foOiKS8IJL/xRlvmjCaHELBz crossorigin=anonymous></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css><script type=text/javascript src=/js/bundle.min.js></script><script type=text/javascript>setupShortcuts(maxLevel=2)</script><script defer data-domain=numpy.org src=https://views.scientific-python.org/js/script.js></script></html>